{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create the transform\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# tokenize and build vocab\u001b[39;00m\n\u001b[0;32m      5\u001b[0m vectorizer\u001b[38;5;241m.\u001b[39mfit(text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'we': 71, 'may': 38, 'be': 6, 'college': 12, 'students': 53, 'perhaps': 44, 'candidates': 10, 'for': 21, 'higher': 27, 'degree': 15, 'and': 2, 'yet': 76, 'realize': 49, 'that': 59, 'what': 72, 'is': 31, 'happening': 24, 'to': 66, 'us': 69, 'stuffing': 54, 'not': 39, 'education': 17, 'there': 63, 'are': 3, 'many': 35, 'who': 73, 'know': 32, 'certainly': 11, 'by': 8, 'the': 60, 'time': 65, 'they': 64, 'get': 23, 'their': 61, 'bachelor': 5, 'spent': 51, 'four': 22, 'years': 75, 'taking': 56, 'courses': 14, 'finishing': 20, 'with': 74, 'them': 62, 'passing': 43, 'examinations': 19, 'mastery': 36, 'attained': 4, 'in': 30, 'process': 48, 'of': 40, 'subject': 55, 'matter': 37, 'but': 7, 'teacher': 57, 'personality': 45, 'if': 29, 'student': 52, 'remembers': 50, 'enough': 18, 'was': 70, 'told': 67, 'him': 28, 'lectures': 33, 'textbooks': 58, 'he': 26, 'has': 25, 'line': 34, 'on': 41, 'pet': 46, 'prejudices': 47, 'can': 9, 'pass': 42, 'course': 13, 'easily': 16, 'also': 0, 'up': 68, 'an': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)\n",
    "# this shows how many times a word has appeared in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 4 1 1 1 1 2 2 1 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 1 3 1 1 2 2 4 1 1 1 1\n",
      "  1 1 1 2 3 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 3 6 1 1 1 2 1 2 1 1 1 1 1\n",
      "  2 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# encode document\n",
    "newvector = vectorizer.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "print(newvector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "Purpose of tf-idf is to highlight words which are frequent in a document but not across documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Frequency\n",
      "the             6\n",
      "and             4\n",
      "is              4\n",
      "he              3\n",
      "that            3\n",
      "...           ...\n",
      "matter          1\n",
      "an              1\n",
      "on              1\n",
      "pass            1\n",
      "yet             1\n",
      "\n",
      "[77 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#ignore it\n",
    "#------------------\n",
    "#--------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "text = \"\"\"We may be college students—perhaps candidates for a higher degree—and yet realize that what is happening to us is stuffing, not education. There are many college students who know, certainly by the time they get their bachelor's degree, that they spent four years taking courses and finishing with them by passing examinations. The mastery attained in that process is not of subject matter, but of the teacher's personality. If the student remembers enough of what was told to him in lectures and textbooks, and if he has a line on the teacher's pet prejudices, he can pass the course easily enough. but he is also passing up an education.\"\"\"\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text\n",
    "word_counts = vectorizer.fit_transform([text])\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "df = pd.DataFrame(word_counts.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Transpose and sort by frequency\n",
    "df = df.T\n",
    "\n",
    "# Rename column and sort\n",
    "df.columns = ['Frequency']\n",
    "df = df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Print word frequencies\n",
    "print(df)\n",
    "\n",
    "#ignore it -------------\n",
    "#-----------------------\n",
    "#-----------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
